{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install kaggle --upgrade"
      ],
      "metadata": {
        "id": "1GEIas-08Q8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem Statement"
      ],
      "metadata": {
        "id": "M-Ib0w_D-o6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extreme weather events are sweeping the globe and range from heat waves, wildfires and drought to hurricanes, extreme rainfall and flooding. These weather events have multiple impacts on agriculture, energy, transportation, as well as low resource communities and disaster planning in countries across the globe.\n",
        "\n",
        "Accurate long-term forecasts of temperature and precipitation are crucial to help people prepare and adapt to these extreme weather events. Currently, purely physics-based models dominate short-term weather forecasting. But these models have a limited forecast horizon. The availability of meteorological data offers an opportunity for data scientists to improve sub-seasonal forecasts by blending physics-based forecasts with machine learning. Sub-seasonal forecasts for weather and climate conditions (lead-times ranging from 15 to more than 45 days) would help communities and industries adapt to the challenges brought on by climate change."
      ],
      "metadata": {
        "id": "iDcfT2Ja-vmV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Description"
      ],
      "metadata": {
        "id": "WldhS0pu-vjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The WiDS Datathon 2023 focuses on a prediction task involving forecasting sub-seasonal temperatures (temperatures over a two-week period, in our case) within the United States. We are using a pre-prepared dataset consisting of weather and climate information for a number of US locations, for a number of start dates for the two-week observation, as well as the forecasted temperature and precipitation from a number of weather forecast models (we will reveal the source of our dataset after the competition closes). Each row in the data corresponds to a single location and a single start date for the two-week period. Your task is to predict the arithmetic mean of the maximum and minimum temperature over the next 14 days, for each location and start date.\n",
        "\n",
        "You are provided with two datasets:\n",
        "\n",
        "train_data.csv: the training dataset, where contest-tmp2m-14d__tmp2m, the arithmetic mean of the max and min observed temperature over the next 14 days for each location and start date, is provided\n",
        "test_data.csv: the test dataset, where we withhold the true value of contest-tmp2m-14d__tmp2m for each row.\n",
        "To participate in the Datathon, you will submit a solution file containing the predicted values of contest-tmp2m-14d__tmp2m for each row in the test dataset. The predicted values you submit will be compared against the observed values for the test dataset and this will determine your standing on the Leaderboard during the competition as well as your final standing when the competition closes.\n",
        "\n",
        "You are also provided with an example of a solution file prepared for submission."
      ],
      "metadata": {
        "id": "eTOt3Zj6-vgR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Dictionary"
      ],
      "metadata": {
        "id": "97y0pLWk-vOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The WiDS 2023 Datathon is using a subset of a pre-prepared dataset in which the variables were gathered from the following datasets (source of the WiDS Datathon dataset will be revealed after the competition closes):\n",
        "\n",
        "Temperature: Daily maximum and minimum temperature measurements at 2 meters from 1979 onwards were obtained from NOAA’s Climate Prediction Center (CPC) Global Gridded Temperature dataset and converted to Celsius. The official contest target temperature variable is tmp2m = tmax+tmin / 2.\n",
        "\n",
        "ftp://ftp.cpc.ncep.noaa.gov/precip/PEOPLE/wd52ws/global_temp/\n",
        "\n",
        "\n",
        "Global precipitation: Daily precipitation data from 1979 onward were obtained from NOAA’s CPC Gauge-Based Analysis of Global Daily Precipitation [42] and converted to mm.\n",
        "\n",
        "ftp://ftp.cpc.ncep.noaa.gov/precip/CPC_UNI_PRCP/GAUGE_GLB/RT/\n",
        "\n",
        "\n",
        "U.S. precipitation: Daily U.S. precipitation data in mm were collected from the CPC Unified Gauge-Based Analysis of Daily Precipitation over CONUS. Measurements were replaced with sums over the ensuing two-week period.\n",
        "\n",
        "https://www.esrl.noaa.gov/psd/thredds/catalog/Datasets/cpc_us_precip/catalog.html\n",
        "\n",
        "\n",
        "Sea surface temperature and sea ice concentration: NOAA’s Optimum Interpolation Sea Surface Temperature (SST) dataset provides SST and sea ice concentration data, daily from 1981 to the present.\n",
        "\n",
        "ftp://ftp.cdc.noaa.gov/Projects/Datasets/noaa.oisst.v2.highres/\n",
        "\n",
        "\n",
        "Multivariate ENSO index (MEI): Bimonthly MEI values (MEI) from 1949 to the present, were obtained from NOAA/Earth System Research Laboratory. The MEI is a scalar summary of six variables (sea-level pressure, zonal and meridional surface wind components, SST, surface air temperature, and sky cloudiness) associated with El Niño/Southern Oscillation (ENSO), an ocean-atmosphere coupled climate mode.\n",
        "\n",
        "https://www.esrl.noaa.gov/psd/enso/mei/\n",
        "\n",
        "\n",
        "Madden-Julian oscillation (MJO): Daily MJO values since 1974 are provided by the Australian Government Bureau of Meteorology. MJO is a metric of tropical convection on daily to weekly timescales and can have a significant impact on the United States sub-seasonal climate. Measurements of phase and amplitude on the target date were extracted over the two-week period.\n",
        "\n",
        "http://www.bom.gov.au/climate/mjo/graphics/rmm.74toRealtime.txt\n",
        "\n",
        "\n",
        "Relative humidity, sea level pressure, and precipitable water for the entire atmosphere: NOAA’s National Center for Environmental Prediction (NCEP)/National Center for Atmospheric Research Reanalysis dataset contains daily relative humidity (rhum) near the surface (sigma level 0.995) from 1948 to the present and daily pressure at the surface (pres) from 1979 to the present.\n",
        "\n",
        "ftp://ftp.cdc.noaa.gov/Datasets/ncep.reanalysis/surface/\n",
        "\n",
        "\n",
        "Geopotential height, zonal wind, and longitudinal wind: To capture polar vortex variability, obtained daily mean geopotential height were obtained at 10mb from the NCEP Reanalysis dataset.\n",
        "\n",
        "ftp://ftp.cdc.noaa.gov/Datasets/ncep.reanalysis.dailyavgs/pressure/\n",
        "\n",
        "\n",
        "North American Multi-Model Ensemble (NMME): The North American Multi-Model Ensemble (NMME) is a collection of physics-based forecast models from various modeling centers in North America. Forecasts issued monthly from the Cansips, CanCM3, CanCM4, CCSM3, CCSM4, GFDL-CM2.1-aer04, GFDL-CM2.5, FLOR-A06 and FLOR-B01, NASA-GMAO-062012, and NCEP-CFSv2 models were downloaded from the IRI/LDEO Climate Data Library. Each forecast contains monthly mean predictions from 0.5 to 8.5 months ahead.\n",
        "\n",
        "https://iridl.ldeo.columbia.edu/SOURCES/.Models/.NMME/\n",
        "\n",
        "\n",
        "Pressure and potential evaporation: ftp://ftp.cdc.noaa.gov/Datasets/ncep.reanalysis/surface_gauss/\n",
        "\n",
        "\n",
        "Elevation: http://research.jisao.washington.edu/data_sets/elevation/elev.1-deg.nc\n",
        "\n",
        "\n",
        "Köppen-Geiger climate classifications: http://koeppen-geiger.vu-wien.ac.at/present.htm\n",
        "\n",
        "Variable naming\n",
        "Each variable name, prefix__suffix, consists of two parts (separated by a double underscore) that inform you of the meaning of the variable. The prefix indicates from which of the above-listed file the variable was derived (e.g. Madden-Julian oscillation, pressure, and potential evaporation from NOAA's surface_gauss etc), the suffix indicates the specific type of information that was extracted from the file.\n",
        "\n",
        "Variable prefixes\n",
        "contest-slp-14d: file containing sea level pressure (slp)\n",
        "\n",
        "nmme0-tmp2m-34w: file containing most recent monthly NMME model forecasts for tmp2m (cancm30,\n",
        "cancm40, ccsm30, ccsm40, cfsv20, gfdlflora0, gfdlflorb0, gfdl0, nasa0,\n",
        "nmme0mean) and average forecast across those models (nmme0mean)\n",
        "\n",
        "contest-pres-sfc-gauss-14d: pressure\n",
        "\n",
        "mjo1d: MJO phase and amplitude\n",
        "\n",
        "contest-pevpr-sfc-gauss-14d: potential evaporation\n",
        "\n",
        "contest-wind-h850-14d: geopotential height at 850 millibars\n",
        "\n",
        "contest-wind-h500-14d: geopotential height at 500 millibars\n",
        "\n",
        "contest-wind-h100-14d: geopotential height at 100 millibars\n",
        "\n",
        "contest-wind-h10-14d: geopotential height at 10 millibars\n",
        "\n",
        "contest-wind-vwnd-925-14d: longitudinal wind at 925 millibars\n",
        "\n",
        "contest-wind-vwnd-250-14d: longitudinal wind at 250 millibars\n",
        "contest-wind-uwnd-250-14d: zonal wind at 250 millibars\n",
        "\n",
        "contest-wind-uwnd-925-14d: zonal wind at 925 millibars\n",
        "\n",
        "contest-rhum-sig995-14d: relative humidity\n",
        "\n",
        "contest-prwtr-eatm-14d: precipitable water for entire atmosphere\n",
        "nmme-prate-34w: weeks 3-4 weighted average of monthly NMME model forecasts for precipitation\n",
        "\n",
        "nmme-prate-56w: weeks 5-6 weighted average of monthly NMME model forecasts for precipitation\n",
        "nmme0-prate-56w: weeks 5-6 weighted average of most recent monthly NMME model forecasts for precipitation\n",
        "\n",
        "nmme0-prate-34w: weeks 3-4 weighted average of most recent monthly NMME model forecasts for precipitation\n",
        "\n",
        "nmme-tmp2m-34w: weeks 3-4 weighted average of most recent monthly NMME model forecasts for target label, contest-tmp2m-14d__tmp2m\n",
        "\n",
        "nmme-tmp2m-56w: weeks 5-6 weighted average of monthly NMME model forecasts for target label, contest-tmp2m-14d__tmp2m\n",
        "\n",
        "mei: MEI (mei), MEI rank (rank), and Niño Index Phase (nip)\n",
        "\n",
        "elevation: elevation\n",
        "\n",
        "contest-precip-14d: measured precipitation\n",
        "\n",
        "climateregions: Köppen-Geigerclimateclassifications\n",
        "\n",
        "Variables without prefix\n",
        "Some variables do not have a prefix. Instead, each variable name in its entirely indicates the information the variable captures.\n",
        "\n",
        "lat: latitude of location (anonymized)\n",
        "lon: longitude of location (anonymized)\n",
        "startdate: startdate of the 14 day period\n",
        "sst: sea surface temperature\n",
        "icec: sea ice concentration\n",
        "cancm30, cancm40, ccsm30, ccsm40, cfsv20, gfdlflora0, gfdlflorb0, gfdl0, nasa0, nmme0mean: most recent forecasts from weather models\n",
        "Target\n",
        "contest-tmp2m-14d__tmp2m: the arithmetic mean of the max and min observed temperature over the next 14 days for each location and start date, computed as (measured max temperature + measured mini temperature) / 2"
      ],
      "metadata": {
        "id": "-4i4HUNw_a7c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Metric"
      ],
      "metadata": {
        "id": "PzRCwvvGBxEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The evaluation metric for this competition is Root Mean Squared Error (RMSE). The RMSE is a commonly used measure of the differences between predicted values provided by a model and the actual observed values.\n",
        "\n",
        "RMSE is computed as:\n",
        "RMSE=1𝑁∑𝑛=1𝑁(𝑦(𝑛)−𝑦̂ (𝑛))2‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾⎷,\n",
        "\n",
        "where\n",
        "𝑦(𝑛)\n",
        "is the n-th observed value and\n",
        "𝑦̂ (𝑛)\n",
        "is the n-th predicted value given by the model."
      ],
      "metadata": {
        "id": "0gH2TYArCEQ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Development"
      ],
      "metadata": {
        "id": "vTw-SNZlCMJQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Environment Setup"
      ],
      "metadata": {
        "id": "fzFkhLxwF9fs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0NHLOFI7AGn"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "\n",
        "# Data Exploration\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Data Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Feature Engineering and model Building\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Model Evaluation \n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, precision_recall_fscore_support\n",
        "\n",
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# !pip install ipyleaflet\n",
        "import ipyleaflet\n",
        "from ipyleaflet import Map\n",
        "\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Exploration"
      ],
      "metadata": {
        "id": "on07Ce78J2mS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data \n",
        "\n",
        "# Train Data\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/Data Project Datasets/Sub_seasonal forecasting/train_data.csv')\n",
        "# Test Data\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Data Project Datasets/Sub_seasonal forecasting/test_data.csv')\n",
        "# Submission Format\n",
        "df_sub = pd.read_csv('/content/drive/MyDrive/Data Project Datasets/Sub_seasonal forecasting/sample_solution.csv')"
      ],
      "metadata": {
        "id": "wGm97K66-T_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.T"
      ],
      "metadata": {
        "id": "WfBfBv4ONWce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "B2DrdR-cZuEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.head()"
      ],
      "metadata": {
        "id": "R4T0wMhaZuB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Viewing Columns\n",
        "df_train.columns"
      ],
      "metadata": {
        "id": "rzZlZTETZt-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.info()"
      ],
      "metadata": {
        "id": "2IUQR8FpZt7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View statistical information of the data\n",
        "df_train.describe()"
      ],
      "metadata": {
        "id": "vmdr2_UTZt4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "8SXrJLDMfzv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['startdate'].dtypes"
      ],
      "metadata": {
        "id": "FsfbVcY7fztM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change datatype of 'startdate' column to (date)\n",
        "df_train['startdate'] = pd.to_datetime(df_train['startdate'])"
      ],
      "metadata": {
        "id": "ueTztMjAfzp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['startdate'].dtypes"
      ],
      "metadata": {
        "id": "ov_LnPKifzm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort Data by 'startdate' column\n",
        "df_train = df_train.sort_values(by = 'startdate', ascending = True)\n",
        "df_train"
      ],
      "metadata": {
        "id": "9yDlwj8sxGgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for Null values\n",
        "df_train.isnull().sum() "
      ],
      "metadata": {
        "id": "xA7unNlDfzjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def per_filter_na_cols(df):\n",
        "    count_na_df = df.isna().sum() \n",
        "    if count_na_df[count_na_df > 0].tolist():\n",
        "        return (count_na_df[count_na_df > 0] / len(df)) * 100 \n",
        "    else:\n",
        "        return 'Clean dataset'"
      ],
      "metadata": {
        "id": "edBNZpz-9moH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "per_filter_na_cols(df_train)"
      ],
      "metadata": {
        "id": "w-3-2BlN93ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in null values\n",
        "df_train[[\"nmme0-tmp2m-34w__ccsm30\",'nmme-tmp2m-56w__ccsm3',\"nmme-prate-34w__ccsm3\",\"nmme0-prate-56w__ccsm30\",\"nmme0-prate-34w__ccsm30\",\"nmme-prate-56w__ccsm3\",\"nmme-tmp2m-34w__ccsm3\",\"ccsm30\"]]"
      ],
      "metadata": {
        "id": "4RabFxtU_3bK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RppVAfKZ-kfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill Null Values\n",
        "df_train['nmme0-tmp2m-34w__ccsm30'].fillna(df_train['nmme0-tmp2m-34w__ccsm30'].mean(), inplace = True)"
      ],
      "metadata": {
        "id": "bGuNz6Xufzgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing = [\"nmme0-tmp2m-34w__ccsm30\",'nmme-tmp2m-56w__ccsm3',\"nmme-prate-34w__ccsm3\",\"nmme0-prate-56w__ccsm30\",\"nmme0-prate-34w__ccsm30\",\"nmme-prate-56w__ccsm3\",\"nmme-tmp2m-34w__ccsm3\",\"ccsm30\"]\n",
        "for df in missing:\n",
        "      df_train[df].fillna(df_train[df].mean(), inplace = True)"
      ],
      "metadata": {
        "id": "j_PkcGnmJyEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "per_filter_na_cols(df_train)"
      ],
      "metadata": {
        "id": "SZsuM6EeMfwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploratory Data Analytics"
      ],
      "metadata": {
        "id": "rAsHyXcbPygr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Target_value = df_train['contest-tmp2m-14d__tmp2m']"
      ],
      "metadata": {
        "id": "NjfYjl7nMyXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize = (10,10))\n",
        "ax.plot(df_train['startdate'],df_train['contest-tmp2m-14d__tmp2m'] )\n"
      ],
      "metadata": {
        "id": "GmaWXH8MQsa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Map(center = [0.833333333333333,0.0454545454545454], zoom= 10)"
      ],
      "metadata": {
        "id": "tnPeWaXHSGzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "water every where\n"
      ],
      "metadata": {
        "id": "6NVReU03j7-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering"
      ],
      "metadata": {
        "id": "NzbzS3TMkFhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['startdate']"
      ],
      "metadata": {
        "id": "WSDn3Pl0n3J7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['year'] = df_train.startdate.dt.year\n",
        "df_train['month'] = df_train.startdate.dt.month\n",
        "df_train['day'] = df_train.startdate.dt.day"
      ],
      "metadata": {
        "id": "v3kGZZmSjKLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "VnwaKsBymtW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(df_train.corr())"
      ],
      "metadata": {
        "id": "zX_KD7oZigR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop Values\n",
        "df_train.drop(['index','startdate'], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "BbtOVITwi2vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "PvOsN4ebx5ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Scale Values\n",
        "# sc = MinMaxScaler()\n",
        "# scaled_df = sc.fit_transform(df_train)"
      ],
      "metadata": {
        "id": "u6KwRYmLyv98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a String column in the dataset and we need to handle it.\n"
      ],
      "metadata": {
        "id": "rpXQlf4w3FV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find string datatype\n",
        "for label, content in df_train.items():\n",
        "    if pd.api.types.is_string_dtype(content):\n",
        "      print(label)"
      ],
      "metadata": {
        "id": "0xa-ELmS0j98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change string datatype to category\n",
        "df_train['climateregions__climateregion'] = df_train['climateregions__climateregion'].astype('category')\n"
      ],
      "metadata": {
        "id": "jNlBD3k_3wRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode category datatype\n",
        "df_train['climateregions__climateregion'] = df_train['climateregions__climateregion'].cat.codes\n"
      ],
      "metadata": {
        "id": "4ojeIN4y45qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "9bN0WiSb-BGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale Values\n",
        "sc = MinMaxScaler()\n",
        "scaled_df = sc.fit_transform(df_train)"
      ],
      "metadata": {
        "id": "VzRw2oqk_X2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_df"
      ],
      "metadata": {
        "id": "S4zdaxAP_e-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_df = pd.DataFrame(scaled_df, columns = df_train.columns)"
      ],
      "metadata": {
        "id": "hNN3KQ7Q_ilt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_df.head()"
      ],
      "metadata": {
        "id": "QGpVgrsh_0vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Data in Dependent and Independednt\n",
        "X = scaled_df.drop('contest-tmp2m-14d__tmp2m', axis = 1)\n",
        "y = scaled_df['contest-tmp2m-14d__tmp2m']"
      ],
      "metadata": {
        "id": "wyIlYrqR_3Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Dimensionality Reduction\n",
        "pca = PCA(n_components = 20)\n",
        "pca_features = pca.fit_transform(X)\n",
        "print('Shape before PCA: ', X.shape)\n",
        "print('Shape before PCA: ', pca_features.shape)"
      ],
      "metadata": {
        "id": "pR_B_TTRCD4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_columns = ['pca_1','pca_2','pca_3','pca_4','pca_5','pca_6','pca_7','pca_8','pca_9','pca_10','pca_11','pca_12','pca_13','pca_14','pca_15','pca_16','pca_17','pca_18','pca_19','pca_20']\n"
      ],
      "metadata": {
        "id": "F86uJ5nkFF-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_X = pd.DataFrame(pca_features, columns = pca_columns)"
      ],
      "metadata": {
        "id": "IlntheG-NzNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_X.head()"
      ],
      "metadata": {
        "id": "brw5QjW-OCzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "f4UHl6iaOGUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split into Train and Validation"
      ],
      "metadata": {
        "id": "h4WBRQPgOaO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Data into train and validation\n",
        "X_train,X_val,y_train,y_val = train_test_split(pca_X,y, \n",
        "                                               test_size= 0.2)"
      ],
      "metadata": {
        "id": "QfG74-I1ORjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape,X_val.shape, y_train.shape, y_val.shape"
      ],
      "metadata": {
        "id": "JrkSUEGNQwaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Building"
      ],
      "metadata": {
        "id": "N-kKMyZ0Rsw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Linear Regression as Baseline\n",
        "LR = LinearRegression()\n",
        "LR.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "O-4cHOxwYGt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using RandomFrorest Algorithm \n",
        "RFR = RandomForestRegressor()\n",
        "RFR.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "dNcqiwjJQ8Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using XGBoost Algorithm\n",
        "xg_model = XGBRegressor()\n",
        "xg_model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "xAftvZcxJjDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation"
      ],
      "metadata": {
        "id": "JwuzTBQ2VQMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Xgboost Algorithm\n",
        "xg_y_preds = xg_model.predict(X_val)\n",
        "xg_MSE = mean_squared_error(y_val,xg_y_preds)\n",
        "print(f\"MSE : {xg_MSE}\")\n",
        "xg_r2 = r2_score(y_val,xg_y_preds)\n",
        "print(f\"R2 : {xg_r2}\")\n",
        "xg_RMSE = np.sqrt(mean_squared_error(y_val,xg_y_preds))\n",
        "print(f\"RMSE : {xg_RMSE}\")\n"
      ],
      "metadata": {
        "id": "mluMTR5gLUaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # RandomForest Algorithm\n",
        "RFR_y_preds = RFR.predict(X_val)\n",
        "RFR_MSE = mean_squared_error(y_val,RFR_y_preds)\n",
        "print(f\"MSE : {RFR_MSE}\")\n",
        "RFR_r2 = r2_score(y_val,RFR_y_preds)\n",
        "print(f\"R2 : {RFR_r2}\")\n",
        "RFR_RMSE = np.sqrt(mean_squared_error(y_val,RFR_y_preds))\n",
        "print(f\"RMSE : {RFR_RMSE}\")"
      ],
      "metadata": {
        "id": "OosFrT8gSLR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # LinearRegression Algorithm\n",
        "LR_y_preds = LR.predict(X_val)\n",
        "LR_MSE = mean_squared_error(y_val,LR_y_preds)\n",
        "print(f\"MSE : {LR_MSE}\")\n",
        "LR_r2 = r2_score(y_val,LR_y_preds)\n",
        "print(f\"R2 : {LR_r2}\")\n",
        "LR_RMSE = np.sqrt(mean_squared_error(y_val,LR_y_preds))\n",
        "print(f\"RMSE : {LR_RMSE}\")"
      ],
      "metadata": {
        "id": "OyRXRVF6VwPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### View Validation Predictions"
      ],
      "metadata": {
        "id": "qMgv2Sb1b8Rn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomForest Predictions\n",
        "predictions_RFR = pd.DataFrame()\n",
        "predictions_RFR['Actual Value'] = y_val\n",
        "predictions_RFR['Random Forest Predictions'] = RFR_y_preds\n",
        "predictions_RFR.head()"
      ],
      "metadata": {
        "id": "QvAax9WvZG7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost Predictions\n",
        "predictions_XGB = pd.DataFrame()\n",
        "predictions_XGB['Actual Value'] = y_val\n",
        "predictions_XGB['Random Forest Predictions'] = xg_y_preds\n",
        "predictions_XGB.head()"
      ],
      "metadata": {
        "id": "ves7MNo3eFPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LinearRegression Predictions\n",
        "predictions_LR = pd.DataFrame()\n",
        "predictions_LR['Actual Value'] = y_val\n",
        "predictions_LR['Random Forest Predictions'] = LR_y_preds\n",
        "predictions_LR.head()"
      ],
      "metadata": {
        "id": "m913Z-hTdOC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Importance"
      ],
      "metadata": {
        "id": "LX1xH0U8L7hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Xgboost\n",
        "xgb.plot_importance(xg_model, ax = plt.gca())"
      ],
      "metadata": {
        "id": "_a4_gq4iL57c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Model"
      ],
      "metadata": {
        "id": "9NNnkGqVSRtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import joblib\n",
        "# joblib.dump(RFR,\"Wind_Model_joblib\")\n"
      ],
      "metadata": {
        "id": "QmoXVIIWfbly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wind_Model = joblib.load(\"Wind_Model_joblib\")"
      ],
      "metadata": {
        "id": "LOU3XtMETfUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing Pipeline"
      ],
      "metadata": {
        "id": "dmkCKXMaUle2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Data\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Data Project Datasets/Sub_seasonal forecasting/test_data.csv')"
      ],
      "metadata": {
        "id": "QiiVzlUceO4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_predictions = df_test.copy()"
      ],
      "metadata": {
        "id": "NSao2rhCvQ9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.head()"
      ],
      "metadata": {
        "id": "K7VU9pZMTnGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "per_filter_na_cols(df_test)"
      ],
      "metadata": {
        "id": "I_y4dcdNdG_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess data (Getting Test Dataset in the same format as training dataset)\n",
        "def preprocess_data(df):\n",
        "    \n",
        "    #Parse TimeStamp\n",
        "    # Change datatype of 'startdate' column to (date)\n",
        "    df['startdate'] = pd.to_datetime(df['startdate'])\n",
        "\n",
        "\n",
        "    #Fill in Numerical Null Columns with the mean\n",
        "    for label, content in df.items():\n",
        "        if pd.api.types.is_float_dtype(content):\n",
        "              if pd.isnull(content).sum():\n",
        "                  df[label] = content.fillna(content.mean())\n",
        "\n",
        "     #Fill in Categorical Null Columns with the mode\n",
        "        if pd.api.types.is_categorical_dtype(content):\n",
        "              if pd.isnull(content).sum():\n",
        "                  df[label] = content.fillna(content.value_counts().index[0])\n",
        "    \n",
        "     # Feature Enginering on Date Column             \n",
        "    df['Year'] = df.startdate.dt.year\n",
        "    df['Month'] = df.startdate.dt.month\n",
        "    df['Day'] = df.startdate.dt.day\n",
        "    \n",
        "    #Convert Object Data Type to Category\n",
        "    for label, content in df.items():\n",
        "        if pd.api.types.is_string_dtype(content):\n",
        "            df[label] = content.astype(\"category\").cat.as_ordered()\n",
        "            \n",
        "                    \n",
        "    # Drop Values\n",
        "    df.drop(['index','startdate'], axis = 1, inplace = True)\n",
        "      \n",
        "                         \n",
        "          \n",
        "    # Encoding Categorical Columns    \n",
        "    for label, content in df.items():\n",
        "        if not pd.api.types.is_numeric_dtype(content):\n",
        "    # We add the +1 because pandas encodes missing categories as -1\n",
        "          df[label] = pd.Categorical(content).codes+1    \n",
        "\n",
        "\n",
        "    # Scale Data\n",
        "    scaled_df = sc.fit_transform(df) \n",
        "    scaled_df = pd.DataFrame(scaled_df, columns = df_test.columns)  \n",
        "\n",
        "    # Perform Dimensionality Reduction\n",
        "    pca_features = pca.fit_transform(scaled_df)  \n",
        "    pca_test_df = pd.DataFrame(pca_features, columns = pca_columns)       \n",
        "              \n",
        "    return pca_test_df"
      ],
      "metadata": {
        "id": "TvGW3bR7WgLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = preprocess_data(df_test)"
      ],
      "metadata": {
        "id": "s0rKZYCNgUea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "A9LCWLjOlGCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = RFR.predict(test)"
      ],
      "metadata": {
        "id": "wkcEEJmDeaBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_predictions.head()"
      ],
      "metadata": {
        "id": "t5TPArXVeyCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_predictions['contest-tmp2m-14d__tmp2m Predictions'] = y_test"
      ],
      "metadata": {
        "id": "8CcuTqc5klvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_predictions"
      ],
      "metadata": {
        "id": "XAH1Yvl1ycpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub"
      ],
      "metadata": {
        "id": "7EYehpF1yfUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_submissions = pd.DataFrame()\n",
        "df_submissions['contest-tmp2m-14d__tmp2m'] = df_predictions['contest-tmp2m-14d__tmp2m Predictions']\n",
        "df_submissions['index'] = df_predictions['index']"
      ],
      "metadata": {
        "id": "adIxi-KAyq9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_submissions.head()"
      ],
      "metadata": {
        "id": "zGkFwGC90Lab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_submissions.to_csv('MLizzys_Wind_Submission.csv')"
      ],
      "metadata": {
        "id": "CYVp8lZD0No5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estimator - **RandomForest Algorithm**\n",
        "\n",
        "RMSE - **0.017**"
      ],
      "metadata": {
        "id": "tT5ICf8n3H9M"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6sBD4tow0cXW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}